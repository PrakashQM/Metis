{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes, resources, other..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhttps://stackoverflow.com/questions/22219004/grouping-rows-in-list-in-pandas-groupby\\n\\n# below creates unique set of keys comprised of first 4 columns (C/A, STATION, UNIT, etc.)\\nnew_set = set(zip(df['C/A'], df['UNIT'], df['SCP'], df['STATION']))\\n\\n# below works as an initial groupby consolidation\\ndf.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE']).count()\\n\\n\\n\\nOBJECTIVES / DELIVERABLES:\\n- could suggest when to host the event based on what part of year we can reach most attendees\\n\\n\\nQUESTIONS:\\n- why would there be significant difference between turnstile entries and exits? Intuitively they would be very similar\\n- \\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/22219004/grouping-rows-in-list-in-pandas-groupby\n",
    "\n",
    "# below creates unique set of keys comprised of first 4 columns (C/A, STATION, UNIT, etc.)\n",
    "new_set = set(zip(df['C/A'], df['UNIT'], df['SCP'], df['STATION']))\n",
    "\n",
    "# below works as an initial groupby consolidation\n",
    "df.groupby(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE']).count()\n",
    "\n",
    "\n",
    "\n",
    "OBJECTIVES / DELIVERABLES:\n",
    "- could suggest when to host the event based on what part of year we can reach most attendees\n",
    "\n",
    "\n",
    "QUESTIONS:\n",
    "- why would there be significant difference between turnstile entries and exits? Intuitively they would be very similar\n",
    "- \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read files into df and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393632 entries, 0 to 199115\n",
      "Data columns (total 11 columns):\n",
      "C/A                                                                     393632 non-null object\n",
      "UNIT                                                                    393632 non-null object\n",
      "SCP                                                                     393632 non-null object\n",
      "STATION                                                                 393632 non-null object\n",
      "LINENAME                                                                393632 non-null object\n",
      "DIVISION                                                                393632 non-null object\n",
      "DATE                                                                    393632 non-null object\n",
      "TIME                                                                    393632 non-null object\n",
      "DESC                                                                    393632 non-null object\n",
      "ENTRIES                                                                 393632 non-null int64\n",
      "EXITS                                                                   393632 non-null int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 36.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "#%matplotlib inline\n",
    "'''\n",
    "# get data file names\n",
    "path ='data/' \n",
    "filenames = glob.glob(path + \"*.txt\")\n",
    "\n",
    "df_list = []\n",
    "for filename in filenames: # remove counter to load all locally available data.\n",
    "    counter = 0\n",
    "    while counter < 2:\n",
    "        df_list.append(pd.read_csv(filename))\n",
    "        counter += 1\n",
    "'''\n",
    "\n",
    "# list of .txt files to be read\n",
    "txt_docs_list = ['turnstile_160409.txt', 'turnstile_180310.txt', 'turnstile_180317.txt',\n",
    "                 'turnstile_180324.txt', 'turnstile_180331.txt', 'turnstile_180407.txt']\n",
    "\n",
    "# reading in the files\n",
    "df_list = []\n",
    "for each in range(2):\n",
    "    df_list.append(pd.read_csv(txt_docs_list[each]))\n",
    "    \n",
    "# concatenating the DFs together as 'df'\n",
    "df = pd.concat(df_list)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
       "       'DESC', 'ENTRIES', 'EXITS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip column headings\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393632 entries, 0 to 199115\n",
      "Data columns (total 13 columns):\n",
      "C/A             393632 non-null object\n",
      "UNIT            393632 non-null object\n",
      "SCP             393632 non-null object\n",
      "STATION         393632 non-null object\n",
      "LINENAME        393632 non-null object\n",
      "DIVISION        393632 non-null object\n",
      "DATE            393632 non-null object\n",
      "TIME            393632 non-null object\n",
      "DESC            393632 non-null object\n",
      "ENTRIES         393632 non-null int32\n",
      "EXITS           393632 non-null int32\n",
      "datetime        393632 non-null datetime64[ns]\n",
      "turnstile_id    393632 non-null object\n",
      "dtypes: datetime64[ns](1), int32(2), object(10)\n",
      "memory usage: 39.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert data types to reduce file size (20% size reduction)\n",
    "#df['C/A'] = df['C/A'].astype('category')\n",
    "#df['DIVISION'] = df['DIVISION'].astype('category')\n",
    "#df['UNIT'] = df['UNIT'].astype('category')\n",
    "df['ENTRIES'] = df['ENTRIES'].astype('int32')\n",
    "df['EXITS'] = df['EXITS'].astype('int32')\n",
    "\n",
    "# ... and DATETIME formatting\n",
    "df['datetime'] = df['DATE'] + ' ' + df['TIME']\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%m/%d/%Y %H:%M:%S')\n",
    "#df['date'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y')\n",
    "#df['time'] = pd.to_datetime(df['TIME'], format='%H:%M:%S')\n",
    "\n",
    "# Concat first four rows (rather than groupby) as unique ID for turnstile\n",
    "df['turnstile_id'] = df['C/A'] + '_' + df['UNIT'] + '_' + df['SCP'] + '_' + df['STATION']\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Derive turnstile counts\n",
    "- Here we introduce groupby to consolidate information based on unique turnstile identifiers (first 4 columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Groupby to get 'df_turnstile' and 'df_station'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(by=['userid','product'])[['userid','price']].groupby(['userid']).diff()\n",
    "#df1_entries = df.sort_values(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE'])[['DATE','ENTRIES']].groupby(['C/A', 'UNIT', 'SCP', 'STATION','DATE']).diff()\n",
    "#df1_entries.reset_index(inplace=True)\n",
    "#df2 = df.sort_values(by=['C/A', 'UNIT', 'SCP', 'STATION'])[['date', 'ENTRIES']].groupby(['date']).diff()\n",
    "#df2.head\n",
    "\n",
    "\n",
    "#df2 = df.set_index(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'TIME'])[['ENTRIES', 'EXITS']].diff()\n",
    "#df2 = df.groupby(['turnstile_id', 'DATE', 'TIME'], as_index=False)[['ENTRIES', 'EXITS']].diff()  <---- does not work\n",
    "#df2.reset_index(inplace=True)\n",
    "#df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^ above a bunch of stuff that didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below gets us the data... but includes wrong values when the unique turnstile rolls over.\n",
    "df2 = df.set_index(['C/A', 'UNIT', 'SCP', 'STATION', 'DATE', 'TIME'])[['ENTRIES', 'EXITS']].diff()\n",
    "df2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those wrong values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv('/Users/jas/Desktop/trialcsv.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_turnstile_day\n",
    "- Eliminated 'datetime' and original 'DATE' and 'TIME' columns here. For future reference..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_turnstile_hour\n",
    "- 1. groupby 'datetime'.sum()\n",
    "- 2. use .resample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 'station' column around which to aggregate/group/summarize\n",
    "- in order to: sum by station by week or month\n",
    "- in order to: sum by station then day of week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAP whats below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build daily turnstile count list (incorporating class's shift method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_turnstile_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea170e0358e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                        \u001b[0;31m#.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                        \u001b[0;31m#.transform(lambda grp: grp.shift(1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m df_turnstile_counts[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (df_turnstile_counts\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                        \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'turnstile_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_entry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                        .transform(lambda grp: grp.shift(1)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_turnstile_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Class shift process cont'd...\n",
    "#turnstiles_daily[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (turnstiles_daily\n",
    "                                                       #.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\n",
    "                                                       #.transform(lambda grp: grp.shift(1)))\n",
    "df_turnstile_counts[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (df_turnstile_counts\n",
    "                                                       .groupby('turnstile_id')['date', 'first_entry']\n",
    "                                                       .transform(lambda grp: grp.shift(1)))\n",
    "df_turnstile_counts['PREV_EXITS'] = (df_turnstile_counts\n",
    "                                                       .groupby('turnstile_id')['first_exit']\n",
    "                                                       .transform(lambda grp: grp.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN rows for last date\n",
    "df_turnstile_counts.dropna(subset=[\"PREV_DATE\"], axis=0, inplace=True)\n",
    "\n",
    "# summarize \n",
    "df_turnstile_counts['shift_entries'] = df_turnstile_counts['first_entry'] - df_turnstile_counts['PREV_ENTRIES']\n",
    "df_turnstile_counts['shift_exits'] = df_turnstile_counts['first_exit'] - df_turnstile_counts['PREV_EXITS']\n",
    "df_turnstile_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DFs summarized by Turnstile and by Station\n",
    "#### Keep in mind the following:\n",
    "- 'date' column type = datetime\n",
    "- 'entries_count' and 'exits_count' are based on Jonathan's list range method\n",
    "- 'shift_entries' and 'shift_exits' are based on the shift method presented in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turnstile Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstile_df = df_turnstile_counts.drop(['entries_list', 'exits_list', 'first_entry', 'first_exit', 'PREV_ENTRIES', 'PREV_EXITS'], axis=1)\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstile_df['station'] = turnstile_df['turnstile_id'].str.slice(19)\n",
    "station_df = turnstile_df.groupby(['station', 'date'])[['entries_count','exits_count', 'entries_exits', 'shift_entries', 'shift_exits']].sum()\n",
    "station_df.reset_index(inplace=True)\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b. Turnstile & Station by HOUR\n",
    " - convert 'TIME' to 'time' as datetime type\n",
    " - track the data by day... grouby(turnstile_id, date, time)\n",
    " -- this will give each recorded time block, usually 4 hour chunks\n",
    " -- how to create hourly data?????\n",
    " - remove day and review ONLY by 'time' block, see if any trends\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby time... (BELOW NOT CURRENTLY BEING USED FOR ANYTHING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove below when rerun all...\n",
    "df['time'] = pd.to_datetime(df['TIME'], format='%H:%M:%S') # remove this when rerun all\n",
    "df_turn_time_counts = df.groupby(['turnstile_id', 'date', 'time']).count()\n",
    "df_turn_time_counts.reset_index(inplace=True)\n",
    "df_turn_time_counts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Start the EDA & Plotting/Visualizing\n",
    "#### How to confirm the counts are correct???\n",
    "- option 1: eliminate row if list contains a 0 or counts through zero\n",
    "- option 2: eliminate row if returns (-) value\n",
    "- option 3: determine max count for the counters and look for values approaching max, this also requires confirming that max count is same across all turnstiles)\n",
    "- option 4: identify the 'reset' value / max count within the list and work with it\n",
    "- option 5: ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "print('mean: ' + str(np.mean(entries_count)))\n",
    "print('median: ' + str(np.median(entries_count)))\n",
    "print('std: ' + str(np.std(entries_count)))\n",
    "\n",
    "#below doesn't quite work, but keeping it close for reference...\n",
    "'''\n",
    "entries_dict = defaultdict(int)\n",
    "for k in entries_count:\n",
    "    entries_dict[k] += 1\n",
    "\n",
    "    \n",
    "pos = np.arange(len(entries_dict.keys()))\n",
    "width = 1.0     # gives histogram aspect to the bar diagram\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xticks(pos + (width / 2))\n",
    "ax.set_xticklabels(entries_dict.keys())\n",
    "    \n",
    "plt.bar(list(entries_dict.keys()), entries_dict.values())\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "plt.hist(entries_count)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
